"""Script transformation utilities for authentic ancient language rendering.

This module provides functions to transform text according to historically authentic
script conventions defined in language_config.py.

Features:
- Case transformation (uppercase/lowercase/mixed)
- Accent and diacritic removal
- V-for-U substitution (Latin)
- Scriptio continua (continuous writing without word spaces)
- Interpunct insertion (ancient word separator Â·)
- Iota subscript â†’ adscript conversion (Greek á¾³ â†’ Î‘Î™)
- Nomina sacra (sacred name abbreviations with overlines for Koine Greek)
"""

from __future__ import annotations

import re
import unicodedata
from typing import TYPE_CHECKING

from app.lesson.language_config import LanguageConfig, get_language_config

if TYPE_CHECKING:
    from app.api.schemas.script_preferences import ScriptDisplayMode


def apply_script_transform(text: str, language_code: str) -> str:
    """Transform text according to language-specific script rules.

    Args:
        text: The text to transform
        language_code: ISO 639-3 language code

    Returns:
        Transformed text following authentic script conventions
    """
    config = get_language_config(language_code)
    return apply_script_transform_with_config(text, config)


def apply_script_transform_with_config(text: str, config: LanguageConfig) -> str:
    """Transform text according to script configuration.

    Args:
        text: The text to transform
        config: Language configuration with script rules

    Returns:
        Transformed text following authentic script conventions
    """
    if not text:
        return text

    result = text

    # Apply character normalizations (e.g., Jâ†’I, Uâ†’V for Latin)
    if config.script.normalize_chars:
        for old_char, new_char in config.script.normalize_chars.items():
            result = result.replace(old_char, new_char)

    # Strip accents/diacritics if not wanted for this language
    if not config.script.has_accents:
        result = _remove_accents(result)

    # Apply case transformation
    if config.script.case == "upper":
        result = result.upper()
    elif config.script.case == "lower":
        result = result.lower()
    # "mixed" case leaves text as-is

    # Legacy support: Apply V for U transformation (Latin)
    # Note: Modern approach uses normalize_chars instead
    if config.script.char_v_for_u and not config.script.normalize_chars:
        result = result.replace("U", "V").replace("u", "v")

    # Apply scriptio continua if default for this language
    if config.script.scriptio_continua_default and config.script.word_separator is None:
        result = apply_scriptio_continua(result)

    # Apply word separator if configured
    if config.script.word_separator:
        result = _apply_word_separator(result, config.script.word_separator)

    return result


def _remove_accents(text: str) -> str:
    """Remove all diacritical marks from text.

    Uses Unicode normalization to decompose characters into base + combining marks,
    then strips the combining marks. Also handles Greek monotonic uppercase letters
    which are precomposed and don't decompose with NFD.

    Args:
        text: Text potentially containing diacritical marks

    Returns:
        Text with all diacritical marks removed
    """
    # Greek monotonic uppercase letters with tonos/dialytika that don't decompose
    # Map them to their unaccented forms
    greek_monotonic_map = {
        "\u0386": "\u0391",  # Î† â†’ Î‘ (Alpha with tonos)
        "\u0388": "\u0395",  # Îˆ â†’ Î• (Epsilon with tonos)
        "\u0389": "\u0397",  # Î‰ â†’ Î— (Eta with tonos)
        "\u038a": "\u0399",  # ÎŠ â†’ Î™ (Iota with tonos)
        "\u038c": "\u039f",  # ÎŒ â†’ ÎŸ (Omicron with tonos)
        "\u038e": "\u03a5",  # ÎŽ â†’ Î¥ (Upsilon with tonos)
        "\u038f": "\u03a9",  # Î â†’ Î© (Omega with tonos)
        "\u03aa": "\u0399",  # Îª â†’ Î™ (Iota with dialytika)
        "\u03ab": "\u03a5",  # Î« â†’ Î¥ (Upsilon with dialytika)
    }

    # Apply Greek monotonic replacements first
    result = text
    for accented, unaccented in greek_monotonic_map.items():
        result = result.replace(accented, unaccented)

    # Normalize to NFD (decomposed form) where accents are separate combining characters
    nfd = unicodedata.normalize("NFD", result)

    # Filter out combining characters (category Mn = Mark, Nonspacing)
    without_accents = "".join(char for char in nfd if unicodedata.category(char) != "Mn")

    # Normalize back to NFC (composed form)
    return unicodedata.normalize("NFC", without_accents)


def convert_iota_subscript_to_adscript(text: str) -> str:
    """Convert Greek iota subscripts to adscripts (full iota).

    Historical note: Ancient Greek inscriptions used full iota (adscript) written
    on the line, not subscript. The subscript form is a medieval innovation.

    Args:
        text: Greek text potentially containing iota subscripts

    Returns:
        Text with iota subscripts converted to full iotas

    Examples:
        >>> convert_iota_subscript_to_adscript("á¾³")
        'Î‘Î™'
        >>> convert_iota_subscript_to_adscript("Ï„á¿· Î»ÏŒÎ³á¿³")
        'Î¤Î©Î™ Î›ÎŸÎ“Î©Î™'
    """
    # Map lowercase iota subscript vowels to vowel + I
    lowercase_map = {
        "á¾€": "Î±Î¹",  # alpha with psili and iota subscript
        "á¾": "Î±Î¹",  # alpha with dasia and iota subscript
        "á¾‚": "Î±Î¹",  # alpha with psili, varia, and iota subscript
        "á¾ƒ": "Î±Î¹",  # alpha with dasia, varia, and iota subscript
        "á¾„": "Î±Î¹",  # alpha with psili, oxia, and iota subscript
        "á¾…": "Î±Î¹",  # alpha with dasia, oxia, and iota subscript
        "á¾†": "Î±Î¹",  # alpha with psili, perispomeni, and iota subscript
        "á¾‡": "Î±Î¹",  # alpha with dasia, perispomeni, and iota subscript
        "á¾°": "Î±",  # alpha with vrachy (no iota but sometimes confused)
        "á¾±": "Î±",  # alpha with macron (no iota)
        "á¾³": "Î±Î¹",  # alpha with iota subscript (MOST COMMON)
        "á¾´": "Î±Î¹",  # alpha with oxia and iota subscript
        "á¾¶": "Î±",  # alpha with perispomeni (no iota)
        "á¾·": "Î±Î¹",  # alpha with perispomeni and iota subscript
        "á¾": "Î·Î¹",  # eta with psili and iota subscript
        "á¾‘": "Î·Î¹",  # eta with dasia and iota subscript
        "á¾’": "Î·Î¹",  # eta with psili, varia, and iota subscript
        "á¾“": "Î·Î¹",  # eta with dasia, varia, and iota subscript
        "á¾”": "Î·Î¹",  # eta with psili, oxia, and iota subscript
        "á¾•": "Î·Î¹",  # eta with dasia, oxia, and iota subscript
        "á¾–": "Î·Î¹",  # eta with psili, perispomeni, and iota subscript
        "á¾—": "Î·Î¹",  # eta with dasia, perispomeni, and iota subscript
        "á¿ƒ": "Î·Î¹",  # eta with iota subscript (MOST COMMON)
        "á¿„": "Î·Î¹",  # eta with oxia and iota subscript
        "á¿†": "Î·",  # eta with perispomeni (no iota)
        "á¿‡": "Î·Î¹",  # eta with perispomeni and iota subscript
        "á¾ ": "Ï‰Î¹",  # omega with psili and iota subscript
        "á¾¡": "Ï‰Î¹",  # omega with dasia and iota subscript
        "á¾¢": "Ï‰Î¹",  # omega with psili, varia, and iota subscript
        "á¾£": "Ï‰Î¹",  # omega with dasia, varia, and iota subscript
        "á¾¤": "Ï‰Î¹",  # omega with psili, oxia, and iota subscript
        "á¾¥": "Ï‰Î¹",  # omega with dasia, oxia, and iota subscript
        "á¾¦": "Ï‰Î¹",  # omega with psili, perispomeni, and iota subscript
        "á¾§": "Ï‰Î¹",  # omega with dasia, perispomeni, and iota subscript
        "á¿³": "Ï‰Î¹",  # omega with iota subscript (MOST COMMON)
        "á¿´": "Ï‰Î¹",  # omega with oxia and iota subscript
        "á¿¶": "Ï‰",  # omega with perispomeni (no iota)
        "á¿·": "Ï‰Î¹",  # omega with perispomeni and iota subscript
    }

    # Map uppercase iota subscript vowels to vowel + Î™
    uppercase_map = {
        "á¾ˆ": "Î‘Î™",  # alpha with psili and prosgegrammeni
        "á¾‰": "Î‘Î™",  # alpha with dasia and prosgegrammeni
        "á¾Š": "Î‘Î™",  # alpha with psili, varia, and prosgegrammeni
        "á¾‹": "Î‘Î™",  # alpha with dasia, varia, and prosgegrammeni
        "á¾Œ": "Î‘Î™",  # alpha with psili, oxia, and prosgegrammeni
        "á¾": "Î‘Î™",  # alpha with dasia, oxia, and prosgegrammeni
        "á¾Ž": "Î‘Î™",  # alpha with psili, perispomeni, and prosgegrammeni
        "á¾": "Î‘Î™",  # alpha with dasia, perispomeni, and prosgegrammeni
        "á¾¼": "Î‘Î™",  # alpha with prosgegrammeni (MOST COMMON)
        "á¾˜": "Î—Î™",  # eta with psili and prosgegrammeni
        "á¾™": "Î—Î™",  # eta with dasia and prosgegrammeni
        "á¾š": "Î—Î™",  # eta with psili, varia, and prosgegrammeni
        "á¾›": "Î—Î™",  # eta with dasia, varia, and prosgegrammeni
        "á¾œ": "Î—Î™",  # eta with psili, oxia, and prosgegrammeni
        "á¾": "Î—Î™",  # eta with dasia, oxia, and prosgegrammeni
        "á¾ž": "Î—Î™",  # eta with psili, perispomeni, and prosgegrammeni
        "á¾Ÿ": "Î—Î™",  # eta with dasia, perispomeni, and prosgegrammeni
        "á¿Œ": "Î—Î™",  # eta with prosgegrammeni (MOST COMMON)
        "á¾¨": "Î©Î™",  # omega with psili and prosgegrammeni
        "á¾©": "Î©Î™",  # omega with dasia and prosgegrammeni
        "á¾ª": "Î©Î™",  # omega with psili, varia, and prosgegrammeni
        "á¾«": "Î©Î™",  # omega with dasia, varia, and prosgegrammeni
        "á¾¬": "Î©Î™",  # omega with psili, oxia, and prosgegrammeni
        "á¾­": "Î©Î™",  # omega with dasia, oxia, and prosgegrammeni
        "á¾®": "Î©Î™",  # omega with psili, perispomeni, and prosgegrammeni
        "á¾¯": "Î©Î™",  # omega with dasia, perispomeni, and prosgegrammeni
        "á¿¼": "Î©Î™",  # omega with prosgegrammeni (MOST COMMON)
    }

    result = text
    for subscript, adscript in lowercase_map.items():
        result = result.replace(subscript, adscript)
    for subscript, adscript in uppercase_map.items():
        result = result.replace(subscript, adscript)

    return result


def apply_scriptio_continua(text: str) -> str:
    """Remove all word spaces to create scriptio continua (continuous writing).

    Historical note: Ancient Greek and Latin texts were written in scriptio continua
    without word separation. Word spaces are a medieval innovation.

    Args:
        text: Text with modern word spacing

    Returns:
        Text with all spaces removed (except line breaks)

    Examples:
        >>> apply_scriptio_continua("ÎœÎ—ÎÎ™Î Î‘Î•Î™Î”Î• Î˜Î•Î‘")
        'ÎœÎ—ÎÎ™ÎÎ‘Î•Î™Î”Î•Î˜Î•Î‘'
        >>> apply_scriptio_continua("ARMA VIRVMQVE CANO")
        'ARMAVIRVMQVECANO'
    """
    # Remove all spaces but preserve line breaks
    return re.sub(r"[ \t]+", "", text)


def apply_interpunct(text: str) -> str:
    """Replace word spaces with interpuncts (middle dots Â·).

    Historical note: Some ancient inscriptions used interpuncts as word separators,
    though this was not universal. More common than scriptio continua in Latin
    inscriptions, less common in Greek.

    Args:
        text: Text with modern word spacing

    Returns:
        Text with spaces replaced by interpuncts

    Examples:
        >>> apply_interpunct("ARMA VIRVMQVE CANO")
        'ARMAÂ·VIRVMQVEÂ·CANO'
        >>> apply_interpunct("ÎœÎ—ÎÎ™Î Î‘Î•Î™Î”Î• Î˜Î•Î‘")
        'ÎœÎ—ÎÎ™ÎÂ·Î‘Î•Î™Î”Î•Â·Î˜Î•Î‘'
    """
    # Replace spaces with interpunct (U+00B7 MIDDLE DOT)
    return re.sub(r" +", "Â·", text.strip())


def _apply_word_separator(text: str, separator: str) -> str:
    """Apply a specific word separator character.

    Args:
        text: Text with spaces
        separator: Character to use as word separator

    Returns:
        Text with spaces replaced by separator
    """
    return re.sub(r" +", separator, text.strip())


def apply_nomina_sacra(text: str, language_code: str = "grc-koi") -> str:
    """Apply nomina sacra (sacred name abbreviations with overlines) to Koine Greek.

    Historical note: Early Christian manuscripts abbreviated sacred names (nomina sacra)
    with a line over the abbreviation. This was a distinctively Christian practice.

    Common nomina sacra:
    - Î˜Î£ (with overline) for Î˜Î•ÎŸÎ£ (God)
    - ÎšÎ£ (with overline) for ÎšÎ¥Î¡Î™ÎŸÎ£ (Lord)
    - Î™Î£ (with overline) for Î™Î—Î£ÎŸÎ¥Î£ (Jesus)
    - Î§Î£ (with overline) for Î§Î¡Î™Î£Î¤ÎŸÎ£ (Christ)
    - Î ÎÎ‘ (with overline) for Î ÎÎ•Î¥ÎœÎ‘ (Spirit)
    - Î¥Î£ (with overline) for Î¥Î™ÎŸÎ£ (Son)
    - Î Î—Î¡ (with overline) for Î Î‘Î¤Î—Î¡ (Father)
    - ÎœÎ—Î¡ (with overline) for ÎœÎ—Î¤Î—Î¡ (Mother)
    - Î‘ÎÎŸÎ£ (with overline) for Î‘ÎÎ˜Î¡Î©Î ÎŸÎ£ (man/human)
    - Î”Î‘Î” (with overline) for Î”Î‘Î¥Î™Î” (David)
    - Î™Î—Î› (with overline) for Î™Î£Î¡Î‘Î—Î› (Israel)
    - Î™Î›Î—Îœ (with overline) for Î™Î•Î¡ÎŸÎ¥Î£Î‘Î›Î—Îœ (Jerusalem)

    Args:
        text: Koine Greek text
        language_code: Should be "grc-koi" (Koine Greek)

    Returns:
        Text with nomina sacra abbreviated and overlined

    Examples:
        >>> apply_nomina_sacra("Î˜Î•ÎŸÎ£", "grc-koi")
        'Î˜ÍžÎ£'
        >>> apply_nomina_sacra("ÎšÎ¥Î¡Î™ÎŸÎ£ Î™Î—Î£ÎŸÎ¥Î£ Î§Î¡Î™Î£Î¤ÎŸÎ£", "grc-koi")
        'ÎšÍžÎ£ Î™ÍžÎ£ Î§ÍžÎ£'
    """
    if language_code != "grc-koi":
        return text  # Only apply to Koine Greek

    # Unicode combining overline: U+035E
    OVERLINE = "\u035e"

    # Nomina sacra mappings (full word â†’ abbreviated form)
    # Format: each letter gets an overline, e.g., Î˜Î£ â†’ Î˜ÍžÎ£Íž
    nomina_sacra = {
        # Most common (15 standard nomina sacra)
        "Î˜Î•ÎŸÎ£": f"Î˜{OVERLINE}Î£{OVERLINE}",  # God
        "Î˜Î•ÎŸÎ¥": f"Î˜{OVERLINE}Î¥{OVERLINE}",  # of God (genitive)
        "Î˜Î•Î©Î": f"Î˜{OVERLINE}Î{OVERLINE}",  # of gods (genitive plural)
        "ÎšÎ¥Î¡Î™ÎŸÎ£": f"Îš{OVERLINE}Î£{OVERLINE}",  # Lord
        "ÎšÎ¥Î¡Î™ÎŸÎ¥": f"Îš{OVERLINE}Î¥{OVERLINE}",  # of Lord (genitive)
        "ÎšÎ¥Î¡Î™Î©Î": f"Îš{OVERLINE}Î{OVERLINE}",  # of lords (genitive plural)
        "Î™Î—Î£ÎŸÎ¥Î£": f"Î™{OVERLINE}Î£{OVERLINE}",  # Jesus
        "Î™Î—Î£ÎŸÎ¥": f"Î™{OVERLINE}Î¥{OVERLINE}",  # of Jesus (genitive)
        "Î§Î¡Î™Î£Î¤ÎŸÎ£": f"Î§{OVERLINE}Î£{OVERLINE}",  # Christ
        "Î§Î¡Î™Î£Î¤ÎŸÎ¥": f"Î§{OVERLINE}Î¥{OVERLINE}",  # of Christ (genitive)
        "Î ÎÎ•Î¥ÎœÎ‘": f"Î {OVERLINE}Î{OVERLINE}Î‘{OVERLINE}",  # Spirit
        "Î ÎÎ•Î¥ÎœÎ‘Î¤ÎŸÎ£": f"Î {OVERLINE}Î{OVERLINE}Î£{OVERLINE}",  # of Spirit (genitive)
        "Î¥Î™ÎŸÎ£": f"Î¥{OVERLINE}Î£{OVERLINE}",  # Son
        "Î¥Î™ÎŸÎ¥": f"Î¥{OVERLINE}Î¥{OVERLINE}",  # of Son (genitive)
        "Î Î‘Î¤Î—Î¡": f"Î {OVERLINE}Î—{OVERLINE}Î¡{OVERLINE}",  # Father
        "Î Î‘Î¤Î¡ÎŸÎ£": f"Î {OVERLINE}Î¡{OVERLINE}Î£{OVERLINE}",  # of Father (genitive)
        "ÎœÎ—Î¤Î—Î¡": f"Îœ{OVERLINE}Î—{OVERLINE}Î¡{OVERLINE}",  # Mother
        "ÎœÎ—Î¤Î¡ÎŸÎ£": f"Îœ{OVERLINE}Î¡{OVERLINE}Î£{OVERLINE}",  # of Mother (genitive)
        "Î‘ÎÎ˜Î¡Î©Î ÎŸÎ£": f"Î‘{OVERLINE}Î{OVERLINE}ÎŸ{OVERLINE}Î£{OVERLINE}",  # man/human
        "Î‘ÎÎ˜Î¡Î©Î ÎŸÎ¥": f"Î‘{OVERLINE}Î{OVERLINE}ÎŸ{OVERLINE}Î¥{OVERLINE}",  # of man (genitive)
        "ÎŸÎ¥Î¡Î‘ÎÎŸÎ£": f"ÎŸ{OVERLINE}Î¥{OVERLINE}Î{OVERLINE}Î£{OVERLINE}",  # heaven
        "ÎŸÎ¥Î¡Î‘ÎÎŸÎ¥": f"ÎŸ{OVERLINE}Î¥{OVERLINE}Î{OVERLINE}Î¥{OVERLINE}",  # of heaven (genitive)
        "Î™Î£Î¡Î‘Î—Î›": f"Î™{OVERLINE}Î—{OVERLINE}Î›{OVERLINE}",  # Israel
        "Î”Î‘Î¥Î™Î”": f"Î”{OVERLINE}Î‘{OVERLINE}Î”{OVERLINE}",  # David
        "Î™Î•Î¡ÎŸÎ¥Î£Î‘Î›Î—Îœ": f"Î™{OVERLINE}Î›{OVERLINE}Î—{OVERLINE}Îœ{OVERLINE}",  # Jerusalem
        "Î£Î¤Î‘Î¥Î¡ÎŸÎ£": f"Î£{OVERLINE}Î¤{OVERLINE}Î£{OVERLINE}",  # cross
    }

    result = text
    # Sort by length (longest first) to avoid partial replacements
    for full_word, abbreviated in sorted(nomina_sacra.items(), key=lambda x: -len(x[0])):
        # Use word boundary matching to avoid replacing parts of words
        result = re.sub(rf"\b{full_word}\b", abbreviated, result)

    return result


def remove_modern_punctuation(text: str, language_code: str) -> str:
    """Remove modern punctuation marks not used in ancient manuscripts.

    Historical note: Ancient Greek and Latin manuscripts did not use modern
    punctuation like commas, periods, question marks, or exclamation marks.
    Some ancient texts used high dots (Â·) for major pauses, but most used
    no punctuation at all.

    Args:
        text: Text potentially containing modern punctuation
        language_code: Language code (e.g., "grc", "lat", "grc-koi")

    Returns:
        Text with modern punctuation removed or replaced

    Examples:
        >>> remove_modern_punctuation("Î§Î‘Î™Î¡Î•, Î© Î¦Î™Î›Î•!", "grc")
        'Î§Î‘Î™Î¡Î• Î© Î¦Î™Î›Î•'
        >>> remove_modern_punctuation("SALVE, AMICE.", "lat")
        'SALVE AMICE'
    """
    # Remove modern punctuation marks
    modern_punctuation = {
        "?": "",  # Question mark (not ancient)
        "!": "",  # Exclamation mark (not ancient)
        ",": " ",  # Comma (replace with space)
        ";": " ",  # Semicolon (especially not ancient Greek - this is modern question mark!)
        ":": " ",  # Colon (not ancient)
        ".": " ",  # Period (not ancient in this form)
        '"': "",  # Quotation marks
        "'": "",  # Apostrophe (except in Greek elision)
        "â€”": " ",  # Em dash
        "â€“": " ",  # En dash
        "(": "",  # Parentheses
        ")": "",
        "[": "",  # Brackets
        "]": "",
    }

    result = text
    for punct, replacement in modern_punctuation.items():
        result = result.replace(punct, replacement)

    # Clean up multiple spaces
    result = re.sub(r" +", " ", result).strip()

    return result


def get_alphabet_for_language(language_code: str) -> list[str]:
    """Get the alphabet/script characters for a language.

    Returns the basic character set used in authentic scripts.
    For languages without predefined alphabets, extracts unique characters
    from the language's native name as a fallback.

    Args:
        language_code: ISO 639-3 language code

    Returns:
        List of characters in the script
    """
    config = get_language_config(language_code)

    # Greek alphabet (uppercase without accents)
    if language_code in ("grc", "grc-koi"):
        return list("Î‘Î’Î“Î”Î•Î–Î—Î˜Î™ÎšÎ›ÎœÎÎžÎŸÎ Î¡Î£Î¤Î¥Î¦Î§Î¨Î©")

    # Latin alphabet (uppercase, with V not U)
    if language_code == "lat":
        return list("ABCDEFGHIKLMNOPQRSTVXYZ")

    # Hebrew alphabet
    if language_code in ("hbo", "hbo-paleo"):
        return list("××‘×’×“×”×•×–×—×˜×™×›×œ×ž× ×¡×¢×¤×¦×§×¨×©×ª")

    # Arabic alphabet (basic forms)
    if language_code == "ara":
        return list("Ø§Ø¨ØªØ«Ø¬Ø­Ø®Ø¯Ø°Ø±Ø²Ø³Ø´ØµØ¶Ø·Ø¸Ø¹ØºÙÙ‚ÙƒÙ„Ù…Ù†Ù‡ÙˆÙŠ")

    # Cyrillic (for Old Church Slavonic)
    if language_code == "cu":
        return list("ÐÐ‘Ð’Ð“Ð”Ð•Ð–Ð—Ð˜Ð†ÐšÐ›ÐœÐÐžÐŸÐ Ð¡Ð¢ÐžÐ£Ð¤Ð¥Ð¦Ð§Ð¨Ð©ÐªÐ«Ð¬Ñ¢Ð®Ñ¦ÑªÑ¨Ñ¬Ñ®Ñ°Ñ²Ñ´")

    # Sanskrit Devanagari alphabet
    if language_code in ("san", "san-ved"):
        return list("à¤…à¤†à¤‡à¤ˆà¤‰à¤Šà¤‹à¥ à¤Œà¥¡à¤à¤à¤“à¤”à¤•à¤–à¤—à¤˜à¤™à¤šà¤›à¤œà¤à¤žà¤Ÿà¤ à¤¡à¤¢à¤£à¤¤à¤¥à¤¦à¤§à¤¨à¤ªà¤«à¤¬à¤­à¤®à¤¯à¤°à¤²à¤µà¤¶à¤·à¤¸à¤¹")

    # Pali (uses various scripts, Devanagari common)
    if language_code == "pli":
        return list("à¤…à¤†à¤‡à¤ˆà¤‰à¤Šà¤à¤“à¤•à¤–à¤—à¤˜à¤™à¤šà¤›à¤œà¤à¤žà¤Ÿà¤ à¤¡à¤¢à¤£à¤¤à¤¥à¤¦à¤§à¤¨à¤ªà¤«à¤¬à¤­à¤®à¤¯à¤°à¤²à¤µà¤¶à¤¸à¤¹")

    # Old Norse (Latin alphabet with additional characters)
    if language_code == "non":
        return list("AÃBDÃEÃ‰FGHIÃJKLMNOPQRSTUÃšVXYÃÃžÃ†Å’")

    # Old English (Anglo-Saxon runes or Latin)
    if language_code == "ang":
        return list("ABCDEFGHILMNOPRSTVXYZÃ†ÃÃžÇ·")

    # Coptic alphabet
    if language_code == "cop":
        return list("â²€â²‚â²„â²†â²ˆâ²Œâ²Žâ²â²’â²”â²–â²˜â²šâ²œâ²žâ² â²¢â²¤â²¦â²¨â²ªâ²¬â²®â²°Ï¢Ï¤Ï¦Ï¨ÏªÏ¬Ï®")

    # Armenian alphabet
    if language_code in ("xcl", "hye"):
        return list("Ô±Ô²Ô³Ô´ÔµÔ¶Ô·Ô¸Ô¹ÔºÔ»Ô¼Ô½Ô¾Ô¿Õ€ÕÕ‚ÕƒÕ„Õ…Õ†Õ‡ÕˆÕ‰ÕŠÕ‹ÕŒÕÕŽÕÕÕ‘Õ’Õ“Õ”Õ•Õ–")

    # Georgian alphabet
    if language_code == "kat":
        return list("áƒáƒ‘áƒ’áƒ“áƒ”áƒ•áƒ–áƒ—áƒ˜áƒ™áƒšáƒ›áƒœáƒáƒžáƒŸáƒ áƒ¡áƒ¢áƒ£áƒ¤áƒ¥áƒ¦áƒ§áƒ¨áƒ©áƒªáƒ«áƒ¬áƒ­áƒ®áƒ¯áƒ°")

    # Gothic alphabet
    if language_code == "got":
        return list("ðŒ°ðŒ±ðŒ²ðŒ³ðŒ´ðŒµðŒ¶ðŒ·ðŒ¸ðŒ¹ðŒºðŒ»ðŒ¼ðŒ½ðŒ¾ðŒ¿ð€ðð‚ðƒð„ð…ð†ð‡ðˆð‰ðŠ")

    # Old Irish (Latin with special characters)
    if language_code == "sga":
        return list("ABCDEFGHILMNOPRSTUVÃ‰ÃÃ“Ãš")

    # Syriac alphabet
    if language_code == "syc":
        return list("ÜÜ’Ü“Ü•Ü—Ü˜Ü™ÜšÜ›ÜÜŸÜ Ü¡Ü¢Ü£Ü¥Ü¦Ü¨Ü©ÜªÜ«Ü¬")

    # Aramaic (similar to Hebrew/Syriac)
    if language_code == "arc":
        return list("ð¡€ð¡ð¡‚ð¡ƒð¡„ð¡…ð¡†ð¡‡ð¡ˆð¡‰ð¡Šð¡‹ð¡Œð¡ð¡Žð¡ð¡ð¡‘ð¡’ð¡“ð¡”ð¡•")

    # Avestan
    if language_code == "ave":
        return list("ð¬€ð¬ð¬‚ð¬ƒð¬„ð¬…ð¬†ð¬‡ð¬ˆð¬‰ð¬Šð¬‹ð¬Œð¬ð¬Žð¬ð¬ð¬‘ð¬’ð¬“ð¬”ð¬•ð¬–ð¬—ð¬˜ð¬™ð¬šð¬›ð¬œð¬ð¬ž")

    # Classical Chinese (sample common radicals/characters)
    if language_code == "lzh":
        return list("ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åäººå¤©åœ°æ°´ç«æœ¨é‡‘åœŸæ—¥æœˆå±±å·")

    # Classical Japanese (sample Kanji + Kana)
    if language_code == "ojp":
        return list("ã‚ã„ã†ãˆãŠã‹ããã‘ã“ã•ã—ã™ã›ããŸã¡ã¤ã¦ã¨ãªã«ã¬ã­ã®")

    # Classical Tibetan
    if language_code == "bod":
        return list("à½€à½à½‚à½„à½…à½†à½‡à½‰à½à½à½‘à½“à½”à½•à½–à½˜à½™à½šà½›à½à½žà½Ÿà½ à½¡à½¢à½£à½¤à½¦à½§à½¨")

    # Classical Nahuatl (Latin alphabet)
    if language_code == "nci":
        return list("ACEHILMNOPQTUVXYZ")

    # Classical Quechua (Latin alphabet)
    if language_code == "qwh":
        return list("ACHIKLMNPQRSTUVWY")

    # Akkadian (cuneiform - using transliteration Latin)
    if language_code == "akk":
        return list("ABDEGHIKLMNPQRSÅ TUVWYZá¹¢á¹¬")

    # Sumerian (cuneiform - using transliteration)
    if language_code == "sux":
        return list("ABDEGHIKLMNPRSTUVZ")

    # Hittite (cuneiform - using transliteration)
    if language_code == "hit":
        return list("ABDEGHIKLMNPRSTUVWZ")

    # Middle Persian/Pahlavi (using Pahlavi script sample)
    if language_code == "pal":
        return list("ð­ ð­¡ð­¢ð­£ð­¤ð­¥ð­¦ð­§ð­¨ð­©ð­ªð­«ð­¬ð­­ð­®ð­¯ð­°ð­±ð­²")

    # Old Egyptian/Middle Egyptian (hieroglyphs - using transliteration)
    if language_code in ("egy-old", "egy"):
        return list("êœ¢BDEFGHá¸¤IKMNPQRSÅ TVWYZ")

    # For any other language, extract unique characters from native name
    # This ensures alphabet tasks can work for all languages
    unique_chars = []
    for char in config.native_name:
        if char.isalpha() and char not in unique_chars:
            unique_chars.append(char)

    # Need at least 4 characters for alphabet task
    if len(unique_chars) >= 4:
        return unique_chars

    # Ultimate fallback - use English alphabet
    return list("ABCDEFGHIJKLMNOPQRSTUVWXYZ")


def apply_script_preferences(
    text: str,
    language_code: str,
    preferences: "ScriptDisplayMode | None" = None,
    authentic_mode: bool = False,
    use_scriptio_continua: bool = False,
    use_interpuncts: bool = False,
    use_iota_adscript: bool = True,
    use_nomina_sacra: bool = False,
    remove_punctuation: bool = False,
) -> str:
    """Apply user script display preferences to text.

    This is the main function for rendering text with user preferences.
    It orchestrates all the transformation functions based on user settings.

    Args:
        text: The text to transform
        language_code: ISO 639-3 language code (e.g., "grc", "lat", "grc-koi")
        preferences: ScriptDisplayMode object with all preferences (if provided, overrides individual params)
        authentic_mode: Apply authentic script transformations (uppercase, no accents, V-for-U)
        use_scriptio_continua: Remove word spaces (continuous writing)
        use_interpuncts: Replace spaces with interpuncts (Â·)
        use_iota_adscript: Convert Greek iota subscripts to adscripts (á¾³ â†’ Î‘Î™)
        use_nomina_sacra: Apply sacred name abbreviations (Koine Greek only)
        remove_punctuation: Remove modern punctuation marks

    Returns:
        Transformed text with all requested transformations applied

    Examples:
        >>> # Modern edition
        >>> apply_script_preferences("Ï‡Î±á¿–ÏÎµ, á½¦ Ï†Î¯Î»Îµ", "grc")
        'Ï‡Î±á¿–ÏÎµ, á½¦ Ï†Î¯Î»Îµ'

        >>> # Authentic mode
        >>> apply_script_preferences("Ï‡Î±á¿–ÏÎµ, á½¦ Ï†Î¯Î»Îµ", "grc", authentic_mode=True)
        'Î§Î‘Î™Î¡Î• Î© Î¦Î™Î›Î•'

        >>> # Authentic with interpuncts
        >>> apply_script_preferences("Ï‡Î±á¿–ÏÎµ, á½¦ Ï†Î¯Î»Îµ", "grc",
        ...                          authentic_mode=True, use_interpuncts=True)
        'Î§Î‘Î™Î¡Î•Â·Î©Â·Î¦Î™Î›Î•'

        >>> # Koine with nomina sacra
        >>> apply_script_preferences("á½ Î¸Îµá½¸Ï‚ ÎºÎ±á½¶ á½ ÎºÏÏÎ¹Î¿Ï‚", "grc-koi",
        ...                          authentic_mode=True, use_nomina_sacra=True)
        'ÎŸ Î˜ÍžÎ£Íž ÎšÎ‘Î™ ÎŸ ÎšÍžÎ£Íž'
    """
    if not text:
        return text

    # If preferences object provided, extract values from it
    if preferences:
        use_scriptio_continua = preferences.use_scriptio_continua
        use_interpuncts = preferences.use_interpuncts
        use_iota_adscript = preferences.use_iota_adscript
        use_nomina_sacra = preferences.use_nomina_sacra
        remove_punctuation = preferences.remove_modern_punctuation

    result = text

    # Step 1: Apply authentic mode transformations (case, accents, V-for-U)
    if authentic_mode:
        result = apply_script_transform(result, language_code)

    # Step 2: Greek iota subscript â†’ adscript conversion (if requested and Greek)
    if use_iota_adscript and language_code in ("grc", "grc-koi"):
        result = convert_iota_subscript_to_adscript(result)

    # Step 3: Remove modern punctuation (if requested)
    if remove_punctuation:
        result = remove_modern_punctuation(result, language_code)

    # Step 4: Apply nomina sacra (Koine Greek only, if requested)
    if use_nomina_sacra and language_code == "grc-koi":
        result = apply_nomina_sacra(result, language_code)

    # Step 5: Word separation (mutually exclusive: scriptio continua OR interpuncts)
    if use_scriptio_continua:
        result = apply_scriptio_continua(result)
    elif use_interpuncts:
        result = apply_interpunct(result)

    return result


def convert_lunate_sigma_to_regular(text: str) -> str:
    """Convert lunate sigma (Ï¹/Ï²) to regular sigma (Î£/Ïƒ).

    Historical note: While lunate sigma was used in some later manuscripts,
    classical Greek inscriptions used only the regular sigma form.
    For authentic classical/Koine display, encode all sigmas as Î£.

    Args:
        text: Greek text potentially containing lunate sigma

    Returns:
        Text with lunate sigma converted to regular sigma

    Examples:
        >>> convert_lunate_sigma_to_regular("ÎšÎ¥Î¡Î™ÎŸÏ¹")
        'ÎšÎ¥Î¡Î™ÎŸÎ£'
        >>> convert_lunate_sigma_to_regular("Ï²Î¿Ï†Î¯Î±")
        'ÏƒÎ¿Ï†Î¯Î±'
    """
    # U+03F9 GREEK CAPITAL LUNATE SIGMA SYMBOL â†’ Î£
    # U+03F2 GREEK LUNATE SIGMA SYMBOL â†’ Ïƒ
    # U+03FD GREEK CAPITAL REVERSED LUNATE SIGMA SYMBOL â†’ Î£
    # U+037C GREEK SMALL DOTTED LUNATE SIGMA SYMBOL â†’ Ïƒ
    # U+037D GREEK SMALL REVERSED DOTTED LUNATE SIGMA SYMBOL â†’ Ïƒ
    replacements = {
        "\u03f9": "Î£",  # GREEK CAPITAL LUNATE SIGMA SYMBOL (Ï¹)
        "\u03f2": "Ïƒ",  # GREEK LUNATE SIGMA SYMBOL (Ï²)
        "\u03fd": "Î£",  # GREEK CAPITAL REVERSED LUNATE SIGMA SYMBOL
        "\u037c": "Ïƒ",  # GREEK SMALL DOTTED LUNATE SIGMA SYMBOL
        "\u037d": "Ïƒ",  # GREEK SMALL REVERSED DOTTED LUNATE SIGMA SYMBOL
    }
    result = text
    for lunate, regular in replacements.items():
        result = result.replace(lunate, regular)
    return result


def preserve_greek_punctuation_unicode(text: str) -> str:
    """Preserve Greek-specific punctuation Unicode code points.

    Important: Some Greek punctuation marks are canonically equivalent to
    Latin punctuation, but should be preserved as distinct code points
    for historical authenticity.

    Args:
        text: Text with potential Greek punctuation

    Returns:
        Text with Greek punctuation Unicode preserved
    """
    # This function would be used AFTER any Unicode normalization
    # to remap back to the Greek-specific code points
    # U+037E (Greek question mark) â‰¡ U+003B (semicolon) - preserve U+037E
    # U+0387 (ano teleia) â‰¡ U+00B7 (middle dot) - preserve U+0387
    # In practice, we ensure these are NEVER normalized away in the first place
    return text


def remove_hebrew_vowel_points(text: str) -> str:
    """Remove Masoretic vowel points (niqqud) and cantillation marks from Hebrew text.

    For authentic Biblical Hebrew display (consonantal text only),
    this removes all later Masoretic additions.

    Args:
        text: Hebrew text potentially with niqqud and te'amim

    Returns:
        Hebrew text with only consonants (and matres lectionis)

    Examples:
        >>> remove_hebrew_vowel_points("×‘Ö°Ö¼×¨Öµ××©Ö´××™×ª")
        '×‘×¨××©×™×ª'
    """
    # Niqqud (vowel points): U+05B0â€“U+05BD, U+05BF, U+05C1â€“U+05C2, U+05C4â€“U+05C5, U+05C7
    # Cantillation marks (te'amim): U+0591â€“U+05AF, U+05BD, U+05BF, U+05C0, U+05C3, U+05C6
    # Also remove other Masoretic marks
    result = text
    # Use NFD to decompose characters
    result = unicodedata.normalize("NFD", result)
    # Remove all combining marks in the Hebrew vowel and cantillation ranges
    result = re.sub(r"[\u0591-\u05C7]", "", result)
    # Normalize back to NFC
    result = unicodedata.normalize("NFC", result)
    return result


def remove_syriac_vowel_points(text: str) -> str:
    """Remove Syriac vowel pointing systems (both Eastern and Western).

    For authentic Classical Syriac (EstrangelÄ), suppress all later
    vowel pointing additions.

    Args:
        text: Syriac text potentially with vowel points

    Returns:
        Syriac text without vowel points

    Examples:
        >>> remove_syriac_vowel_points("Ü¡Ü°Ü ÜŸÜ³Ü")
        'Ü¡Ü ÜŸÜ'
    """
    # Syriac vowel points and diacritics: U+0730â€“U+074A
    result = text
    result = unicodedata.normalize("NFD", result)
    result = re.sub(r"[\u0730-\u074A]", "", result)
    result = unicodedata.normalize("NFC", result)
    return result


def remove_arabic_diacritics_full(text: str) -> str:
    """Remove all Arabic diacritics (á¸¥arakÄt, Å¡adda, tanwÄ«n, etc.).

    For authentic early Quranic rasm (consonantal skeleton), remove all
    vowel marks and diacritical points.

    Args:
        text: Arabic text with diacritics

    Returns:
        Arabic text as consonantal skeleton (rasm)

    Examples:
        >>> remove_arabic_diacritics_full("Ø¨ÙØ³Ù’Ù…Ù Ø§Ù„Ù„ÙŽÙ‘Ù‡Ù")
        'Ø¨Ø³Ù… Ø§Ù„Ù„Ù‡'
    """
    # Arabic diacritics: U+064Bâ€“U+065F (á¸¥arakÄt, tanwÄ«n, Å¡adda, sukÅ«n, etc.)
    # Optional: Also remove consonantal diacritical dots for full rasm authenticity
    # (This would be a separate toggle)
    result = text
    result = unicodedata.normalize("NFD", result)
    # Remove all Arabic diacritical marks
    result = re.sub(r"[\u064B-\u065F]", "", result)
    result = unicodedata.normalize("NFC", result)
    return result


def apply_latin_character_normalization(text: str) -> str:
    """Apply Latin character normalizations for Classical Latin.

    Normalizations:
    - J â†’ I
    - U â†’ V
    - W â†’ VV
    - Ã† â†’ AE
    - Å’ â†’ OE

    Args:
        text: Latin text with modern characters

    Returns:
        Latin text with classical character inventory

    Examples:
        >>> apply_latin_character_normalization("IVLIVS")
        'IVLIVS'
        >>> apply_latin_character_normalization("JULIUS")
        'IULIUS'
        >>> apply_latin_character_normalization("CÃ†SAR")
        'CAESAR'
    """
    normalizations = {
        "J": "I",
        "j": "i",
        "U": "V",
        "u": "v",
        "W": "VV",
        "w": "vv",
        "Ã†": "AE",
        "Ã¦": "ae",
        "Å’": "OE",
        "Å“": "oe",
    }
    result = text
    for old, new in normalizations.items():
        result = result.replace(old, new)
    return result


def apply_ethiopic_word_separator(text: str) -> str:
    """Apply Ethiopic wordspace (á¡) between words for GeÊ½ez.

    Args:
        text: Ethiopic text with spaces

    Returns:
        Text with spaces replaced by Ethiopic wordspace

    Examples:
        >>> apply_ethiopic_word_separator("áŒá‹•á‹ á‰‹áŠ•á‰‹")
        'áŒá‹•á‹á¡á‰‹áŠ•á‰‹'
    """
    # Replace spaces with ETHIOPIC WORDSPACE U+1361
    return re.sub(r" +", "á¡", text.strip())


def apply_tibetan_tsheg(text: str) -> str:
    """Apply Tibetan tsheg (à¼‹) after each syllable.

    Args:
        text: Tibetan text

    Returns:
        Text with tsheg properly placed

    Note:
        This is a simplified version. In practice, proper tsheg placement
        requires understanding Tibetan syllable structure.
    """
    # Simplified: add tsheg after spaces if not already present
    # Full implementation would require Tibetan syllable analysis
    result = text
    if "à¼‹" not in result:
        result = re.sub(r" +", "à¼‹", result)
    return result


def apply_ugaritic_word_divider(text: str) -> str:
    """Apply Ugaritic word divider (ðŽŸ) between every word.

    Args:
        text: Ugaritic text with spaces

    Returns:
        Text with Ugaritic word divider between words

    Examples:
        >>> apply_ugaritic_word_divider("ðŽœðŽ‚ðŽ—ðŽš ðŽ›ðŽ")
        'ðŽœðŽ‚ðŽ—ðŽšðŽŸðŽ›ðŽ'
    """
    # Replace spaces with UGARITIC WORD DIVIDER U+1039F
    return re.sub(r" +", "ðŽŸ", text.strip())


def apply_gothic_interpunct(text: str) -> str:
    """Apply Gothic mandatory interpunct (Â·) between words.

    Args:
        text: Gothic text with spaces

    Returns:
        Text with interpunct between words

    Examples:
        >>> apply_gothic_interpunct("ðŒ²ðŒ¿ð„ðŒ¹ðƒðŒº ð‚ðŒ°ðŒ¶ðŒ³ðŒ°")
        'ðŒ²ðŒ¿ð„ðŒ¹ðƒðŒºÂ·ð‚ðŒ°ðŒ¶ðŒ³ðŒ°'
    """
    # Gothic uses middle dot (U+00B7) between words per Codex Argenteus
    return re.sub(r" +", "Â·", text.strip())


def apply_ogham_markers(text: str) -> str:
    """Add Ogham start and end marks to text.

    Args:
        text: Ogham text

    Returns:
        Text wrapped with Ogham start (áš›) and end (ášœ) marks

    Examples:
        >>> apply_ogham_markers("ášŒáš‘áš”áš‡áš“áš‚áš‰")
        'áš›ášŒáš‘áš”áš‡áš“áš‚áš‰ášœ'
    """
    # Add OGHAM START MARK U+169B and END MARK U+169C
    if not text.startswith("áš›"):
        text = "áš›" + text
    if not text.endswith("ášœ"):
        text = text + "ášœ"
    return text


def validate_script_authenticity(text: str, language_code: str) -> bool:
    """Check if text follows authentic script conventions for the language.

    Args:
        text: Text to validate
        language_code: ISO 639-3 language code

    Returns:
        True if text appears to follow script conventions
    """
    if not text:
        return True

    config = get_language_config(language_code)

    # Check case conventions
    if config.script.case == "upper":
        # Should be mostly uppercase
        upper_ratio = sum(1 for c in text if c.isupper()) / max(1, sum(1 for c in text if c.isalpha()))
        if upper_ratio < 0.8:  # Allow some flexibility
            return False

    # Check for U in Latin text when V should be used
    if config.script.char_v_for_u:
        if "U" in text or "u" in text:
            return False

    return True
